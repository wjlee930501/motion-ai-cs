"""
LLM ë¶„ì„ê¸°

ì´ì „ ì´í•´ë¥¼ ë¡œë“œí•˜ê³  ìƒˆë¡œìš´ ì´í•´ë¥¼ í˜•ì„±í•˜ì—¬ ì €ì¥.
ìë™ ìŠ¹ì¸, ì •í™•ë„ ì¶”ì , Slack ì•Œë¦¼ í¬í•¨.
"""

import json
import logging
import re
import httpx
from datetime import datetime
from typing import Dict, Any, Optional, Tuple, List
from sqlalchemy.orm import Session
from sqlalchemy import func
from anthropic import Anthropic

from shared.config import get_settings
from shared.models import (
    CSUnderstanding,
    LearningExecution,
    ClassificationFeedback,
    PatternApplicationLog,
    MessageEvent,
    LLMAnnotation,
)
from .prompts import SYSTEM_PROMPT, build_user_prompt

logger = logging.getLogger(__name__)
settings = get_settings()

_client: Optional[Anthropic] = None


def get_anthropic_client() -> Anthropic:
    global _client
    if _client is None:
        _client = Anthropic(api_key=settings.anthropic_api_key)
    return _client


def get_feedback_summary(
    db: Session, since_version: Optional[int] = None
) -> Dict[str, Any]:
    """ì´ì „ í•™ìŠµ ì´í›„ ìˆ˜ì§‘ëœ í”¼ë“œë°± ìš”ì•½"""
    query = db.query(ClassificationFeedback).filter(
        ClassificationFeedback.corrected_intent.isnot(None)
    )

    if since_version:
        query = query.filter(
            (ClassificationFeedback.applied_to_version.is_(None))
            | (ClassificationFeedback.applied_to_version > since_version)
        )

    feedbacks = query.all()

    if not feedbacks:
        return {"total": 0, "patterns": []}

    pattern_counts: Dict[str, Dict] = {}
    for fb in feedbacks:
        key = f"{fb.original_intent}â†’{fb.corrected_intent}"
        if key not in pattern_counts:
            pattern_counts[key] = {
                "from_intent": fb.original_intent,
                "to_intent": fb.corrected_intent,
                "count": 0,
                "examples": [],
            }
        pattern_counts[key]["count"] += 1

    patterns = sorted(pattern_counts.values(), key=lambda x: x["count"], reverse=True)

    return {"total": len(feedbacks), "patterns": patterns[:10]}


def parse_learning_output(llm_output: str) -> Tuple[str, Optional[Dict]]:
    """LLM ì¶œë ¥ì—ì„œ í…ìŠ¤íŠ¸ì™€ JSON ë¶„ë¦¬"""

    if "---JSON_OUTPUT---" not in llm_output:
        return llm_output, None

    parts = llm_output.split("---JSON_OUTPUT---")
    understanding_text = parts[0].strip()

    if len(parts) < 2:
        return understanding_text, None

    try:
        json_str = parts[1].strip()

        if json_str.startswith("```"):
            lines = json_str.split("\n")
            start_idx = 1
            end_idx = len(lines)
            for i, line in enumerate(lines):
                if i > 0 and line.strip().startswith("```"):
                    end_idx = i
                    break
            json_str = "\n".join(lines[start_idx:end_idx])
            if json_str.startswith("json"):
                json_str = json_str[4:].strip()

        key_insights = json.loads(json_str)

        if validate_key_insights(key_insights):
            return understanding_text, key_insights
        else:
            logger.warning("key_insights validation failed")
            return understanding_text, None

    except json.JSONDecodeError as e:
        logger.warning(f"Failed to parse key_insights JSON: {e}")
        return understanding_text, None
    except Exception as e:
        logger.warning(f"Unexpected error parsing key_insights: {e}")
        return understanding_text, None


def validate_key_insights(insights: Dict) -> bool:
    """key_insights JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦"""
    required_keys = [
        "internal_discussion_markers",
        "confirmation_patterns",
        "skip_llm_candidates",
        "new_intent_candidates",
    ]

    for key in required_keys:
        if key not in insights:
            logger.warning(f"Missing required key in key_insights: {key}")
            return False
        if not isinstance(insights[key], list):
            logger.warning(f"key_insights[{key}] must be a list")
            return False

    for pattern in insights.get("skip_llm_candidates", []):
        conf = pattern.get("confidence", 0)
        if not isinstance(conf, (int, float)) or not 0 <= conf <= 1:
            logger.warning(f"Invalid confidence in skip_llm_candidates: {conf}")
            return False

        regex = pattern.get("pattern", "")
        try:
            re.compile(regex)
        except re.error as e:
            logger.warning(f"Invalid regex pattern: {regex} - {e}")
            return False

    return True


def extract_and_save_patterns(
    db: Session, understanding_version: int, key_insights: Dict
) -> List[Dict]:
    """key_insightsì—ì„œ íŒ¨í„´ ì¶”ì¶œ í›„ ì €ì¥. ê³ ì‹ ë¢°ë„ skip_llm íŒ¨í„´ì€ ìë™ ìŠ¹ì¸."""
    patterns_to_save = []
    auto_approved_count = 0

    for candidate in key_insights.get("skip_llm_candidates", []):
        if (
            candidate.get("confidence", 0) >= 0.9
            and candidate.get("example_count", 0) >= 3
        ):
            # ê³ ì‹ ë¢°ë„(â‰¥0.95) + ì¶©ë¶„í•œ ì˜ˆì‹œ(â‰¥5) â†’ ìë™ ìŠ¹ì¸ í›„ë³´
            is_auto = (
                candidate.get("confidence", 0) >= 0.95
                and candidate.get("example_count", 0) >= 5
            )

            # ìë™ ìŠ¹ì¸ ì•ˆì „ ê²€ì‚¬: ë„ˆë¬´ ë„“ì€ íŒ¨í„´ ê±°ë¶€
            if is_auto:
                pattern_str = candidate.get("pattern", "")
                # ìµœì†Œ ê¸¸ì´ ë¯¸ë‹¬, ì™€ì¼ë“œì¹´ë“œë§Œ ìˆëŠ” íŒ¨í„´, ë¹ˆ íŒ¨í„´ â†’ ìˆ˜ë™ ê²€í† ë¡œ ì „í™˜
                if (
                    len(pattern_str) < 3
                    or pattern_str in (".*", ".+", "^.*$", "^.+$")
                    or not pattern_str
                ):
                    logger.warning(
                        f"Auto-approval rejected for overly broad pattern: '{pattern_str}'"
                    )
                    is_auto = False

            patterns_to_save.append({
                "pattern_type": "skip_llm",
                "pattern_data": candidate,
                "auto_approved": is_auto,
            })
            if is_auto:
                auto_approved_count += 1

    for marker in key_insights.get("internal_discussion_markers", []):
        if marker.get("confidence", 0) >= 0.85:
            patterns_to_save.append(
                {"pattern_type": "internal_marker", "pattern_data": marker, "auto_approved": False}
            )

    for pattern in key_insights.get("confirmation_patterns", []):
        if pattern.get("confidence", 0) >= 0.85:
            patterns_to_save.append(
                {"pattern_type": "confirmation", "pattern_data": pattern, "auto_approved": False}
            )

    for intent in key_insights.get("new_intent_candidates", []):
        if intent.get("frequency", 0) >= 30 and intent.get("confidence", 0) >= 0.7:
            patterns_to_save.append(
                {"pattern_type": "new_intent", "pattern_data": intent, "auto_approved": False}
            )

    now = datetime.utcnow()
    for pattern in patterns_to_save:
        is_auto = pattern.get("auto_approved", False)
        log = PatternApplicationLog(
            understanding_version=understanding_version,
            pattern_type=pattern["pattern_type"],
            pattern_data=pattern["pattern_data"],
            status="approved" if is_auto else "pending",
            auto_approved=is_auto,
            reviewed_at=now if is_auto else None,
        )
        db.add(log)

    if patterns_to_save:
        db.commit()
        logger.info(
            f"Saved {len(patterns_to_save)} patterns "
            f"({auto_approved_count} auto-approved, "
            f"{len(patterns_to_save) - auto_approved_count} pending review)"
        )

    return patterns_to_save


def calculate_accuracy_metrics(
    db: Session, since_version: int
) -> Optional[Dict[str, Any]]:
    """
    íŠ¹ì • ë²„ì „ ì´í›„ ë¶„ë¥˜ëœ ì´ë²¤íŠ¸ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°.

    correction_rate = ì‹¤ì œ ìˆ˜ì •ëœ ì´ë²¤íŠ¸ ìˆ˜ / í•´ë‹¹ ê¸°ê°„ ë¶„ë¥˜ëœ ì´ë²¤íŠ¸ ìˆ˜
    accuracy = 1 - correction_rate

    correctionsëŠ” event_id ê¸°ì¤€ìœ¼ë¡œ LLMAnnotationê³¼ ê°™ì€ ë²”ìœ„ì—ì„œ ê³„ì‚°.
    """
    try:
        # í•´ë‹¹ ë²„ì „ì˜ CSUnderstanding ìƒì„± ì‹œì  ì¡°íšŒ
        understanding = db.query(CSUnderstanding).filter(
            CSUnderstanding.version == since_version
        ).first()

        if not understanding or not understanding.created_at:
            return None

        since_date = understanding.created_at

        # ë‹¤ìŒ ë²„ì „ì´ ìˆìœ¼ë©´ ê·¸ ì‹œì ê¹Œì§€ë§Œ ì¸¡ì • (ë²„ì „ ê°„ êµ¬ê°„ í•œì •)
        next_understanding = db.query(CSUnderstanding).filter(
            CSUnderstanding.version == since_version + 1
        ).first()
        until_date = next_understanding.created_at if next_understanding else None

        # í•´ë‹¹ êµ¬ê°„ì— ë¶„ë¥˜ëœ ì´ë²¤íŠ¸ ìˆ˜ (target_type='event')
        classified_query = db.query(func.count(LLMAnnotation.id)).filter(
            LLMAnnotation.target_type == "event",
            LLMAnnotation.created_at >= since_date,
        )
        if until_date:
            classified_query = classified_query.filter(
                LLMAnnotation.created_at < until_date
            )
        total_classified = classified_query.scalar() or 0

        if total_classified == 0:
            return None

        # ê°™ì€ êµ¬ê°„ì—ì„œ ì´ë²¤íŠ¸ ë¶„ë¥˜ì— ëŒ€í•œ í”¼ë“œë°± ìˆ˜ì • ê±´ìˆ˜
        corrections_query = db.query(
            func.count(ClassificationFeedback.id)
        ).filter(
            ClassificationFeedback.corrected_at >= since_date,
            ClassificationFeedback.feedback_type == "correction",
        )
        if until_date:
            corrections_query = corrections_query.filter(
                ClassificationFeedback.corrected_at < until_date
            )
        corrections = corrections_query.scalar() or 0

        correction_rate = corrections / total_classified
        accuracy = 1.0 - correction_rate

        return {
            "total_classified": total_classified,
            "corrections": corrections,
            "correction_rate": round(correction_rate, 4),
            "accuracy": round(max(accuracy, 0.0), 4),  # ìŒìˆ˜ ë°©ì§€ (corrections > classified ê°€ëŠ¥)
        }

    except Exception as e:
        logger.error(f"Failed to calculate accuracy metrics: {e}")
        return None


def send_learning_slack_notification(
    version: int,
    logs_analyzed: int,
    auto_approved_count: int,
    pending_count: int,
    accuracy_data: Optional[Dict] = None,
    prev_accuracy: Optional[float] = None,
) -> None:
    """í•™ìŠµ ì™„ë£Œ í›„ Slack ì›¹í›…ìœ¼ë¡œ ìš”ì•½ ì „ì†¡"""
    webhook_url = settings.slack_webhook_url
    if not webhook_url:
        logger.info("[Slack] No webhook URL configured, skipping notification")
        return

    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"ğŸ§  í•™ìŠµ ì™„ë£Œ - v{version}",
            },
        },
        {
            "type": "section",
            "fields": [
                {"type": "mrkdwn", "text": f"*ë¶„ì„ ë©”ì‹œì§€:*\n{logs_analyzed:,}ê±´"},
                {"type": "mrkdwn", "text": f"*ìë™ìŠ¹ì¸ íŒ¨í„´:*\n{auto_approved_count}ê°œ"},
                {"type": "mrkdwn", "text": f"*ìˆ˜ë™ìŠ¹ì¸ ëŒ€ê¸°:*\n{pending_count}ê°œ"},
            ],
        },
    ]

    if accuracy_data:
        accuracy_pct = f"{accuracy_data['accuracy'] * 100:.1f}%"
        accuracy_text = f"*ì´ì „ ë²„ì „ ì •í™•ë„:*\n{accuracy_pct}"
        if prev_accuracy is not None:
            diff = accuracy_data["accuracy"] - prev_accuracy
            arrow = "ğŸ“ˆ" if diff > 0 else "ğŸ“‰" if diff < 0 else "â¡ï¸"
            accuracy_text += f" ({arrow} {diff * 100:+.1f}%p)"
        blocks.append({
            "type": "section",
            "fields": [
                {"type": "mrkdwn", "text": accuracy_text},
                {"type": "mrkdwn", "text": f"*ìˆ˜ì • ê±´ìˆ˜:*\n{accuracy_data['corrections']}ê±´"},
            ],
        })

    try:
        resp = httpx.post(
            webhook_url,
            json={"blocks": blocks},
            timeout=10.0,
        )
        if resp.status_code == 200:
            logger.info(f"[Slack] Learning notification sent for v{version}")
        else:
            logger.warning(f"[Slack] Webhook returned {resp.status_code}")
    except Exception as e:
        logger.error(f"[Slack] Failed to send notification: {e}")


def analyze_and_save(
    db: Session, logs_text: str, log_meta: Dict[str, Any]
) -> Dict[str, Any]:
    """LLM ë¶„ì„ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥"""

    previous = get_latest_understanding(db)
    previous_text = previous.understanding_text if previous else None
    previous_version = previous.version if previous else 0

    logger.info(f"Previous understanding: v{previous_version}")

    feedback_summary = get_feedback_summary(db, previous_version)
    if feedback_summary["total"] > 0:
        logger.info(f"Including {feedback_summary['total']} feedback items in learning")

    user_prompt = build_user_prompt(
        previous_understanding=previous_text,
        logs_text=logs_text,
        log_count=log_meta["count"],
        date_from=log_meta["date_from"],
        date_to=log_meta["date_to"],
        feedback_summary=feedback_summary if feedback_summary["total"] > 0 else None,
        total_available=log_meta.get("total_available"),
        rooms_included=log_meta.get("rooms_included"),
    )

    client = get_anthropic_client()

    logger.info("Calling LLM for understanding formation...")
    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=6000,
        system=SYSTEM_PROMPT,
        messages=[{"role": "user", "content": user_prompt}],
    )

    if not response.content or not hasattr(response.content[0], 'text'):
        raise ValueError("LLM returned empty or non-text response")
    raw_output = response.content[0].text
    understanding_text, key_insights = parse_learning_output(raw_output)

    new_version = previous_version + 1

    # ì´ì „ ë²„ì „ ì •í™•ë„ ê³„ì‚°
    accuracy_data = None
    prev_accuracy_score = None
    if previous_version > 0:
        accuracy_data = calculate_accuracy_metrics(db, previous_version)
        if accuracy_data:
            # ì´ì „ ë²„ì „ì˜ accuracy_score ì—…ë°ì´íŠ¸
            prev_understanding = db.query(CSUnderstanding).filter(
                CSUnderstanding.version == previous_version
            ).first()
            if prev_understanding:
                prev_accuracy_score = float(prev_understanding.accuracy_score) if prev_understanding.accuracy_score else None
                prev_understanding.accuracy_score = accuracy_data["accuracy"]
                db.commit()
                logger.info(
                    f"Updated v{previous_version} accuracy: {accuracy_data['accuracy']:.4f} "
                    f"({accuracy_data['corrections']}/{accuracy_data['total_classified']} corrections)"
                )

    new_understanding = CSUnderstanding(
        version=new_version,
        logs_analyzed_count=log_meta["count"],
        logs_date_from=log_meta["date_from"],
        logs_date_to=log_meta["date_to"],
        understanding_text=understanding_text,
        key_insights=key_insights,
        model_used="claude-sonnet-4-20250514",
        prompt_tokens=response.usage.input_tokens,
        completion_tokens=response.usage.output_tokens,
    )
    db.add(new_understanding)
    db.commit()

    auto_approved_count = 0
    pending_pattern_count = 0
    if key_insights:
        patterns_saved = extract_and_save_patterns(db, new_version, key_insights)
        auto_approved_count = sum(1 for p in patterns_saved if p.get("auto_approved"))
        pending_pattern_count = len(patterns_saved) - auto_approved_count
        logger.info(f"Extracted {len(patterns_saved)} patterns from key_insights")

        # auto_approved_patterns_count ì—…ë°ì´íŠ¸
        new_understanding.auto_approved_patterns_count = auto_approved_count
        db.commit()

    if feedback_summary["total"] > 0:
        db.query(ClassificationFeedback).filter(
            ClassificationFeedback.applied_to_version.is_(None)
        ).update({ClassificationFeedback.applied_to_version: new_version})
        db.commit()
        logger.info(
            f"Marked {feedback_summary['total']} feedbacks as applied to v{new_version}"
        )

    logger.info(
        f"Saved understanding v{new_version} "
        f"(tokens: {response.usage.input_tokens} in, {response.usage.output_tokens} out)"
    )

    # Slack ì•Œë¦¼ ì „ì†¡
    send_learning_slack_notification(
        version=new_version,
        logs_analyzed=log_meta["count"],
        auto_approved_count=auto_approved_count,
        pending_count=pending_pattern_count,
        accuracy_data=accuracy_data,
        prev_accuracy=prev_accuracy_score,
    )

    return {
        "version": new_version,
        "understanding": understanding_text,
        "key_insights": key_insights,
        "feedback_applied": feedback_summary["total"],
        "auto_approved_patterns": auto_approved_count,
        "accuracy": accuracy_data,
    }


def get_latest_understanding(db: Session) -> Optional[CSUnderstanding]:
    return db.query(CSUnderstanding).order_by(CSUnderstanding.version.desc()).first()


def save_execution_history(
    db: Session,
    status: str,
    trigger_type: str,
    duration_seconds: int = None,
    understanding_version: int = None,
    error_message: str = None,
) -> LearningExecution:
    execution = LearningExecution(
        status=status,
        trigger_type=trigger_type,
        duration_seconds=duration_seconds,
        understanding_version=understanding_version,
        error_message=error_message,
    )
    db.add(execution)
    db.commit()

    return execution
